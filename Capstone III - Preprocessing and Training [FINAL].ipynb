{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries and packages\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string \n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and read QA text\n",
    "f = open('Chatbot Document.txt', 'r', errors = 'ignore')\n",
    "text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PREPROCESSING</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert text to sentences (i.e., create sentence tokens)\n",
    "text_sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "#Convert text to list of words (i.e., create word tokens)\n",
    "text_words = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function takes in tokens and returns base word\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatization(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "#Function takes in text and returns word tokens (lowercase and without punctuation)\n",
    "#Translate function replaces punctuation replaced with None\n",
    "punctuation_dictionary = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def prepare_corpus(text):\n",
    "    return lemmatization(nltk.word_tokenize(text.lower().translate(punctuation_dictionary))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>QUIZBOT STUDY SESSION QUESTIONS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start of study session; questions hard-coded\n",
    "start_session = [\"start\", \n",
    "                 \"begin\", \n",
    "                 \"question\", \n",
    "                 \"next question\", \n",
    "                 \"next\"]\n",
    "\n",
    "study_questions = [\"What is logistic regression?\", \n",
    "                \"What is collaborative filtering?\", \n",
    "                \"What is one way to select K for K-means?\", \n",
    "                \"What is entropy?\"]\n",
    "\n",
    "#Function returns a question \n",
    "#If word used by user in start session list, function returns a random question in study_questions list\n",
    "def question(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in start_session:\n",
    "            return random.choice(study_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ANSWER CHECK GENERATION</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate  function accepts 1 parameter (i.e., user_input)\n",
    "def generate_bot_answer(user_input):\n",
    "    quizbot_answer = ''\n",
    "    \n",
    "    #Initialize vectorizer with prepare_corpus tokenizer and stop word removal\n",
    "    vectorizer = TfidfVectorizer(tokenizer = prepare_corpus, stop_words = 'english')  \n",
    "    \n",
    "    #Vectorizer fits to \"training data\"\n",
    "    #Learns vocabulary from text_sentences and calculates idf\n",
    "    #Maps features to idf values\n",
    "    vectorizer.fit(text_sentences) \n",
    "    \n",
    "    #Convert tokenized text to 2D feature matrix (i.e., document-term matrix)\n",
    "    matrix = vectorizer.transform(text_sentences)\n",
    "    \n",
    "    #Debugging\n",
    "    #print(\"debug start\")\n",
    "    \n",
    "    #Check attributes/methods to figure out hot to calculate idf values\n",
    "    #print(dir(vectorizer))\n",
    "    \n",
    "    #Check length of array \n",
    "    #print(vectorizer.idf_.shape)\n",
    "    \n",
    "    #Calculate idf values\n",
    "    #print(vectorizer.idf_)\n",
    "    \n",
    "    #Initialize cosine similarity function\n",
    "    #CS used to measure similarity between user input and corpus\n",
    "    cs_values = cosine_similarity(matrix[-1], matrix)\n",
    "    \n",
    "    \n",
    "    #Debugging\n",
    "    #print(\"debug start\")\n",
    "    \n",
    "    #Check type\n",
    "    #print(type(cs_values))\n",
    "    \n",
    "    #Check original shape of array\n",
    "    #print(cs_values.shape)\n",
    "    \n",
    "    #Check to ensure array has been flattened (2D --> 1D)\n",
    "    #print(cs_values.flatten().shape) \n",
    "    \n",
    "    #Sort feature vectors by respective cosine similarity values and select most related (i.e., highest cs values)\n",
    "    #Leaves out the user input [at index -1 since highest cosine similarity (i.e., equals 1, perfect match)]\n",
    "    #idx indicates *position* of the second highest cosine similarity value\n",
    "    match_position = cs_values.argsort()[0][-2]\n",
    "    \n",
    "    #Flattened 2D to 1D array and selects best match\n",
    "    #Need to flatten otherwise will return a list instead of float (i.e., cosine similarity value)\n",
    "    #req_tfidf returns the actual cosine similarity value at index -2\n",
    "    flattened_matrix = cs_values.flatten()\n",
    "    flattened_matrix.sort()\n",
    "    matched_value = flattened_matrix[-2]\n",
    "    \n",
    "    #If cosine similarity equals 0, there are no similarities between the user input and corpus\n",
    "    #Bot responds \"I don't understand\"\n",
    "    if matched_value == 0:\n",
    "        quizbot_answer = quizbot_answer + \"I am sorry! I don't understand you!\"\n",
    "        return quizbot_answer\n",
    "    \n",
    "    #If cosine similarity is nonzero, return matching sentence in response to query (i.e., sentence at index -2)\n",
    "    else:\n",
    "        quizbot_answer = quizbot_answer + text_sentences[match_position]\n",
    "        return quizbot_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>STUDY SESSION</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuizBot: Welcome! If you want to end the study session, just type bye!\n",
      "start\n",
      "QuizBot: What is logistic regression?\n",
      "Logistic regression is a statistical model used to find the relationships that exist between a dependent binary variable and one or more independent variables.\n",
      "QuizBot: Logistic regression is a statistical model used to find the relationships that exist between a dependent binary variable and one or more independent variables.\n",
      "next\n",
      "QuizBot: What is one way to select K for K-means?\n",
      "The most popular method for selecting k for the k-means algorithm is using the elbow method.\n",
      "QuizBot: The most popular method for selecting k for the k-means algorithm is using the elbow method.\n",
      "next\n",
      "QuizBot: What is collaborative filtering?\n",
      "Based on user activity\n",
      "QuizBot: Collaborative filtering is a form of content filtering that uses similarities between different users to make recommendations.\n",
      "next\n",
      "QuizBot: What is entropy?\n",
      "Entropy is a chemical term, measure of disorder.\n",
      "QuizBot: Entropy is a measure of the level of uncertainty or impurity that’s present in a dataset.\n",
      "next\n",
      "QuizBot: What is collaborative filtering?\n",
      "next\n",
      "QuizBot: What is one way to select K for K-means?\n",
      "Eenie Meenie Miney Mo\n",
      "QuizBot: I am sorry! I don't understand you!\n",
      "bye\n",
      "QuizBot: Bye! See you later!\n"
     ]
    }
   ],
   "source": [
    "#Start of session\n",
    "#Initialize the session variable as true to start the session.\n",
    "session = True\n",
    "print(\"QuizBot: Welcome! If you want to end the study session, just type bye!\")\n",
    "\n",
    "#Session\n",
    "#The conversation will continue until session is false.\n",
    "#If user input indicates start of session, respond with question\n",
    "while session == True:\n",
    "    user_input = input()\n",
    "    \n",
    "    #User input converted to lowercase prior to addition to sentence corpus\n",
    "    user_input = user_input.lower()\n",
    "    if user_input != 'bye':\n",
    "        if question(user_input) != None:\n",
    "            print(\"QuizBot: \" + question(user_input))\n",
    "        \n",
    "        #User input appended to text_sentences and tokenized (i.e., preprocessed) for cosine similarity\n",
    "        else:\n",
    "            text_sentences.append(user_input)\n",
    "            text_words = text_words + nltk.word_tokenize(user_input)\n",
    "            all_words = list(set(text_words))\n",
    "            \n",
    "            #Bot answer is generated, user can compare answers\n",
    "            print(\"QuizBot: \", end = \"\")\n",
    "            print(generate_bot_answer(user_input))\n",
    "            \n",
    "            #After bot response is generated, user input is removed from sentence corpus\n",
    "            text_sentences.remove(user_input)\n",
    "                \n",
    "    #End of Session\n",
    "    #Session set to false if user enters 'bye'; breaks out of while loop and ends session.\n",
    "    else:\n",
    "        session = False\n",
    "        print(\"QuizBot: Bye! See you later!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>APPENDIX</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answers\n",
    "#What is logistic regression?\n",
    "#Logistic regression is a statistical model used to find the relationships that exist between a dependent binary variable and one or more independent variables.\n",
    "#What is collaborative filtering?\n",
    "#Collaborative filtering is a form of content filtering that uses similarities between different users to make recommendations.\n",
    "#What is one way to select K for K-means?\n",
    "#The most popular method for selecting k for the k-means algorithm is using the elbow method.\n",
    "#What is entropy?\n",
    "#Entropy is a measure of the level of uncertainty or impurity that’s present in a dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
